{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor for Bike Sharing UCI Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable,Name,Role,Type,Description,Units,Missing Values\n",
    "1. instant,ID,Integer,record index,,no\n",
    "2. dteday,Feature,Date,date,,no\n",
    "3. season,Feature,Categorical,1:winter, 2:spring, 3:summer, 4:fall,,no\n",
    "4. yr,Feature,Categorical,year (0: 2011, 1: 2012),,no\n",
    "5. mnth,Feature,Categorical,month (1 to 12),,no\n",
    "6. hr,Feature,Categorical,hour (0 to 23),,no\n",
    "7. holiday,Feature,Binary,weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule),,no\n",
    "8. weekday,Feature,Categorical,day of the week,,no\n",
    "9. workingday,Feature,Binary,if day is neither weekend nor holiday is 1, otherwise is 0,,no\n",
    "10. weathersit,Feature,Categorical,- 1: Clear, Few clouds, Partly cloudy, Partly cloudy,,no\n",
    "11. temp,Feature,Continuous,Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale),C,no\n",
    "12. atemp,Feature,Continuous,Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale),C,no\n",
    "13. hum,Feature,Continuous,Normalized humidity. The values are divided to 100 (max),,no\n",
    "14. windspeed,Feature,Continuous,Normalized wind speed. The values are divided to 67 (max),,no\n",
    "15. casual,Other,Integer,count of casual users,,no\n",
    "16. registered,Other,Integer,count of registered users,,no\n",
    "17. cnt,Target,Integer,count of total rental bikes including both casual and registered,,no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 275, 'name': 'Bike Sharing', 'repository_url': 'https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/275/data.csv', 'abstract': 'This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.', 'area': 'Social Science', 'tasks': ['Regression'], 'characteristics': ['Multivariate'], 'num_instances': 17389, 'num_features': 13, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['cnt'], 'index_col': ['instant'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2013, 'last_updated': 'Sun Mar 10 2024', 'dataset_doi': '10.24432/C5W894', 'creators': ['Hadi Fanaee-T'], 'intro_paper': {'ID': 422, 'type': 'NATIVE', 'title': 'Event labeling combining ensemble detectors and background knowledge', 'authors': 'Hadi Fanaee-T, JoÃ£o Gama', 'venue': 'Progress in Artificial Intelligence', 'year': 2013, 'journal': None, 'DOI': '10.1007/s13748-013-0040-3', 'URL': 'https://www.semanticscholar.org/paper/bc42899f599d31a5d759f3e0a3ea8b52479d6423', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. \\r\\n\\r\\nApart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv\\r\\n\\t\\r\\n\\t- instant: record index\\r\\n\\t- dteday : date\\r\\n\\t- season : season (1:winter, 2:spring, 3:summer, 4:fall)\\r\\n\\t- yr : year (0: 2011, 1:2012)\\r\\n\\t- mnth : month ( 1 to 12)\\r\\n\\t- hr : hour (0 to 23)\\r\\n\\t- holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\\r\\n\\t- weekday : day of the week\\r\\n\\t- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\\r\\n\\t+ weathersit : \\r\\n\\t\\t- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\\r\\n\\t\\t- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\\r\\n\\t\\t- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\\r\\n\\t\\t- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\\r\\n\\t- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\\r\\n\\t- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\\r\\n\\t- hum: Normalized humidity. The values are divided to 100 (max)\\r\\n\\t- windspeed: Normalized wind speed. The values are divided to 67 (max)\\r\\n\\t- casual: count of casual users\\r\\n\\t- registered: count of registered users\\r\\n\\t- cnt: count of total rental bikes including both casual and registered\\r\\n', 'citation': None}}\n",
      "          name     role         type demographic  \\\n",
      "0      instant       ID      Integer        None   \n",
      "1       dteday  Feature         Date        None   \n",
      "2       season  Feature  Categorical        None   \n",
      "3           yr  Feature  Categorical        None   \n",
      "4         mnth  Feature  Categorical        None   \n",
      "5           hr  Feature  Categorical        None   \n",
      "6      holiday  Feature       Binary        None   \n",
      "7      weekday  Feature  Categorical        None   \n",
      "8   workingday  Feature       Binary        None   \n",
      "9   weathersit  Feature  Categorical        None   \n",
      "10        temp  Feature   Continuous        None   \n",
      "11       atemp  Feature   Continuous        None   \n",
      "12         hum  Feature   Continuous        None   \n",
      "13   windspeed  Feature   Continuous        None   \n",
      "14      casual    Other      Integer        None   \n",
      "15  registered    Other      Integer        None   \n",
      "16         cnt   Target      Integer        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                        record index  None             no  \n",
      "1                                                date  None             no  \n",
      "2                1:winter, 2:spring, 3:summer, 4:fall  None             no  \n",
      "3                             year (0: 2011, 1: 2012)  None             no  \n",
      "4                                     month (1 to 12)  None             no  \n",
      "5                                      hour (0 to 23)  None             no  \n",
      "6   weather day is holiday or not (extracted from ...  None             no  \n",
      "7                                     day of the week  None             no  \n",
      "8   if day is neither weekend nor holiday is 1, ot...  None             no  \n",
      "9   - 1: Clear, Few clouds, Partly cloudy, Partly ...  None             no  \n",
      "10  Normalized temperature in Celsius. The values ...     C             no  \n",
      "11  Normalized feeling temperature in Celsius. The...     C             no  \n",
      "12  Normalized humidity. The values are divided to...  None             no  \n",
      "13  Normalized wind speed. The values are divided ...  None             no  \n",
      "14                              count of casual users  None             no  \n",
      "15                          count of registered users  None             no  \n",
      "16  count of total rental bikes including both cas...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "bike_sharing = fetch_ucirepo(id=275)\n",
    "X = bike_sharing.data.features\n",
    "y = bike_sharing.data.targets\n",
    "print(bike_sharing.metadata)\n",
    "print(bike_sharing.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler,PolynomialFeatures,PowerTransformer\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"dteday\"]=pd.to_datetime(x[\"dteday\"])\n",
    "x[\"timestamp\"]=x.apply(lambda row: pd.Timestamp(row[\"dteday\"]) + pd.to_timedelta(row[\"hr\"], unit='h'), axis=1)\n",
    "x[\"timestamp\"]=x[\"timestamp\"].astype(\"int64\")//10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"dom\"]=x[\"dteday\"].dt.day\n",
    "x.drop(\"dteday\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"hour_sin\"]=np.sin(2*np.pi*x[\"hr\"]/24)\n",
    "x[\"hour_cos\"]=np.cos(2*np.pi*x[\"hr\"]/24)\n",
    "x[\"month_sin\"]=np.sin(2*np.pi*x[\"mnth\"]/12)\n",
    "x[\"month_cos\"]=np.cos(2*np.pi*x[\"mnth\"]/12)\n",
    "x[\"dom_sin\"]=np.sin(2*np.pi*x[\"dom\"]/30.4585)\n",
    "x[\"dom_cos\"]=np.cos(2*np.pi*x[\"dom\"]/30.4585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d=train_test_split(x,y[\"cnt\"],test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1496.9149296892983"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestRegressor(n_jobs=-1)\n",
    "model.fit(a,c)\n",
    "preds=model.predict(b)\n",
    "mean_squared_error(d,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance=permutation_importance(model,b,d, n_repeats=10, random_state=1)\n",
    "feature_importance=pd.DataFrame({\"Feature\": a.columns, \"Importance\": perm_importance.importances_mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1495.0017225834295\n"
     ]
    }
   ],
   "source": [
    "ai=a[feature_importance[feature_importance[\"Importance\"]>0][\"Feature\"]]\n",
    "bi=b[feature_importance[feature_importance[\"Importance\"]>0][\"Feature\"]]\n",
    "model.fit(ai,c)\n",
    "preds=model.predict(bi)\n",
    "print(mean_squared_error(d,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605.6042446202532\n"
     ]
    }
   ],
   "source": [
    "poly=PolynomialFeatures(degree=2)\n",
    "a_=pd.DataFrame(poly.fit_transform(a))\n",
    "b_=poly.transform(b)\n",
    "model.fit(a_,c)\n",
    "preds=model.predict(b_)\n",
    "print(mean_squared_error(d,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623.6773578826237\n"
     ]
    }
   ],
   "source": [
    "poly=PolynomialFeatures(degree=2, interaction_only=True)\n",
    "a_=poly.fit_transform(a)\n",
    "b_=poly.transform(b)\n",
    "names=poly.get_feature_names_out(input_features=a.columns)\n",
    "a_=pd.DataFrame(data=a_, columns=names)\n",
    "b_=pd.DataFrame(data=b_, columns=names)\n",
    "model.fit(a_,c)\n",
    "preds=model.predict(b_)\n",
    "mse=mean_squared_error(d,preds)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638.1357468066742\n",
      "1569.237510356732\n",
      "1596.9524989643269\n"
     ]
    }
   ],
   "source": [
    "rs=RobustScaler()\n",
    "ms=MinMaxScaler()\n",
    "ss=StandardScaler()\n",
    "for i in [rs,ms,ss]:\n",
    "    ac=i.fit_transform(a_)\n",
    "    ac=pd.DataFrame(data=ac,columns=a_.columns)\n",
    "    bc=i.transform(b_)\n",
    "    bc=pd.DataFrame(data=bc,columns=a_.columns) \n",
    "    model.fit(ac,c)\n",
    "    preds=model.predict(bc)\n",
    "    print(mean_squared_error(d,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance = permutation_importance(model,b_,d, n_repeats=10, random_state=1)\n",
    "feature_importance=pd.DataFrame({\"Feature\": a_.columns, \"Importance\": perm_importance.importances_mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680.5562847813578\n"
     ]
    }
   ],
   "source": [
    "ai_=a_[feature_importance[feature_importance[\"Importance\"]>0][\"Feature\"]]\n",
    "bi_=b_[feature_importance[feature_importance[\"Importance\"]>0][\"Feature\"]]\n",
    "model.fit(ai_,c)\n",
    "preds=model.predict(bi_)\n",
    "print(mean_squared_error(d,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday Before:  5.600461351032705\n",
      "holiday After:  0.0\n",
      "workingday Before:  -0.7757142815812474\n",
      "workingday After:  0.7757142815812469\n",
      "weathersit Before:  1.2318362420718578\n",
      "weathersit After:  0.6759882552420668\n",
      "windspeed Before:  0.5517372130317661\n",
      "windspeed After:  0.007060154121852272\n"
     ]
    }
   ],
   "source": [
    "def inverset(x):\n",
    "    return 1/(x+1)\n",
    "pwrt=PowerTransformer(method=\"yeo-johnson\")\n",
    "boxt=FunctionTransformer(lambda x: boxcox(x)[0],validate=False)\n",
    "logt=FunctionTransformer(np.log1p)\n",
    "invt=FunctionTransformer(inverset)\n",
    "sqrr=FunctionTransformer(np.sqrt)\n",
    "\n",
    "for i in a.columns:\n",
    "    j=a[i].skew()\n",
    "    ap=(a[i],b[i])\n",
    "    if j<=-0.5:\n",
    "        print(i,\"Before: \",j)\n",
    "        if (a[i] <= 0).any() or (b[i] <= 0).any():\n",
    "            a[i] = a[i] + abs(a[i].min())\n",
    "            b[i] = b[i] + abs(a[i].min())\n",
    "        try:\n",
    "            iT=invt.fit_transform(a[i])\n",
    "            it=invt.transform(b[i])\n",
    "        except:\n",
    "            iT=a[i]\n",
    "            it=b[i]\n",
    "        try:\n",
    "            bT=boxt.fit_transform(a[i])\n",
    "            bTD=pd.Series(data=bT,name=i)\n",
    "            bt=boxt.transform(b[i])\n",
    "            btd=pd.Series(data=bt,name=i)\n",
    "        except:\n",
    "            bTD=a[i]\n",
    "            btd=b[i]\n",
    "        try:\n",
    "            sT=sqrr.fit_transform(a[i])\n",
    "            st=sqrr.transform(b[i])\n",
    "        except:\n",
    "            sT=a[i]\n",
    "            st=b[i]\n",
    "        ap=sorted([(iT,it),(sT,st),(bTD,btd), ap], key=lambda x:abs(x[0].skew()))\n",
    "        a[i]=ap[0][0]\n",
    "        b[i]=ap[0][1]\n",
    "        print(i,\"After: \",a[i].skew())\n",
    "    elif j>=0.5:\n",
    "        print(i,\"Before: \",j)\n",
    "        if (a[i] <= 0).any() or (b[i] <= 0).any():\n",
    "            a[i] = a[i] + abs(a[i].min()+1)\n",
    "            b[i] = b[i] + abs(a[i].min()+1)\n",
    "        try:\n",
    "\n",
    "            lT=logt.fit_transform(a[i])\n",
    "            lt=logt.transform(b[i])\n",
    "        except:\n",
    "            lT=a[i]\n",
    "            lt=b[i]\n",
    "        try:\n",
    "            sT=sqrr.fit_transform(a[i])            \n",
    "            st=sqrr.transform(b[i])\n",
    "        except:\n",
    "            sT=a[i]\n",
    "            st=b[i]\n",
    "        try:        \n",
    "            bT=boxt.fit_transform(a[i])\n",
    "            bt=boxt.transform(b[i])\n",
    "            bTD=pd.Series(data=bT,name=i)\n",
    "            btd=pd.Series(data=bt,name=i)\n",
    "        except:\n",
    "            bTD=a[i]\n",
    "            btd=b[i]\n",
    "        try:        \n",
    "            zT=pwrt.fit_transform(np.array(a[i]).reshape(-1,1))\n",
    "            zt=pwrt.transform(np.array(b[i]).reshape(-1,1))\n",
    "            zTD=pd.Series(data=zT.ravel(),name=i)\n",
    "            ztd=pd.Series(data=zt.ravel(),name=i)\n",
    "        except:\n",
    "            xTD=a[i]\n",
    "            ztd=b[i]\n",
    "        ap=sorted([(lT,lt),(sT,st),(bTD,btd),(zTD,ztd), ap], key=lambda x:abs(x[0].skew()))\n",
    "        a[i]=ap[0][0]\n",
    "        b[i]=ap[0][1]\n",
    "        print(i,\"After: \",a[i].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714.6806250575373\n"
     ]
    }
   ],
   "source": [
    "model.fit(a,c)\n",
    "preds=model.predict(b)\n",
    "print(mean_squared_error(d,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712.825222733666\n",
      "1724.5932781357883\n",
      "1736.6232327387802\n"
     ]
    }
   ],
   "source": [
    "for i in [rs,ms,ss]:\n",
    "    ac=i.fit_transform(a)\n",
    "    ac=pd.DataFrame(data=ac,columns=a.columns)\n",
    "    bc=i.transform(b)\n",
    "    bc=pd.DataFrame(data=bc,columns=a.columns) \n",
    "    model.fit(ac,c)\n",
    "    preds=model.predict(bc)\n",
    "    print(mean_squared_error(d,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d=train_test_split(x,y[\"cnt\"],test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631.40007287112\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'ccp_alpha': [0.0001,0.001,0.01,0.1,1],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "rf = RandomForestRegressor(n_jobs=-1, random_state=1)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=7, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(a,c)\n",
    "best=grid_search.best_estimator_\n",
    "pred=best.predict(b)\n",
    "print(mean_squared_error(d,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
